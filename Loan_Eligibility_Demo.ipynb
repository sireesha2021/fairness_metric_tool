{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFi0AcRnpP3OBFwaGx+SMM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sireesha2021/fairness_metric_tool/blob/main/Loan_Eligibility_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KOnGcRg1jo9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "bc99a663-c4e4-4ecd-bcf5-8aa8c595165d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from fairlearn) (1.15.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.17.0)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fairlearn\n",
            "Successfully installed fairlearn-0.12.0\n",
            "Libraries loaded successfully and Fairlearn installed!\n",
            "\n",
            "Synthetic Dataset Head:\n",
            "   Gender   Race  Age        Income  CreditScore    LoanAmount  \\\n",
            "0    Male  White   49  52029.026137   719.223476  18476.829110   \n",
            "1  Female  White   53  14072.956715   688.526257  14857.509276   \n",
            "2  Female  Asian   67  53324.620577   660.622824   9860.402742   \n",
            "3  Female  White   54  24007.105356   700.445533  19450.146388   \n",
            "4    Male  Asian   65  45704.022777   642.490659  -1323.179143   \n",
            "\n",
            "   True_Eligibility  \n",
            "0               1.0  \n",
            "1               1.0  \n",
            "2               1.0  \n",
            "3               1.0  \n",
            "4               0.0  \n",
            "\n",
            "True Eligibility Distribution:\n",
            "True_Eligibility\n",
            "1.0    0.7996\n",
            "0.0    0.2004\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2049056392.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Split data (we'll use test set for audit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# --- Train a simple Logistic Regression model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# For fairness metrics and visualizations (we'll use this later)\n",
        "!pip install fairlearn\n",
        "import fairlearn.metrics as fl_metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Libraries loaded successfully and Fairlearn installed!\")\n",
        "\n",
        "# --- Generate Synthetic Data ---\n",
        "np.random.seed(42)\n",
        "n_samples = 5000\n",
        "\n",
        "# Sensitive Attributes\n",
        "genders = np.random.choice(['Male', 'Female', 'Non-binary'], n_samples, p=[0.48, 0.50, 0.02])\n",
        "races = np.random.choice(['White', 'Black', 'Asian', 'Hispanic'], n_samples, p=[0.6, 0.2, 0.1, 0.1])\n",
        "ages = np.random.randint(18, 70, n_samples) # Age between 18 and 69\n",
        "\n",
        "# Financial Attributes (correlated with eligibility)\n",
        "income = np.random.normal(loc=50000, scale=15000, size=n_samples)\n",
        "credit_score = np.random.normal(loc=680, scale=50, size=n_samples)\n",
        "loan_amount_requested = np.random.normal(loc=15000, scale=5000, size=n_samples)\n",
        "\n",
        "# Introduce some simulated bias in 'true' eligibility (Y) for demo purposes\n",
        "# For example, let's make Black individuals and Non-binary individuals slightly less 'truly' eligible (Y=1)\n",
        "true_eligibility = np.zeros(n_samples)\n",
        "\n",
        "# Base eligibility rate\n",
        "base_prob = 0.6\n",
        "\n",
        "# Adjust based on income and credit score (more likely to be truly eligible with higher income/score)\n",
        "prob_income = (income - np.min(income)) / (np.max(income) - np.min(income)) * 0.2\n",
        "prob_credit = (credit_score - np.min(credit_score)) / (np.max(credit_score) - np.min(credit_score)) * 0.3\n",
        "\n",
        "# Introduce simulated bias for 'true' eligibility\n",
        "for i in range(n_samples):\n",
        "    current_prob = base_prob + prob_income[i] + prob_credit[i]\n",
        "\n",
        "    if races[i] == 'Black':\n",
        "        current_prob -= 0.2 # Lower true eligibility for Black individuals\n",
        "    if genders[i] == 'Non-binary':\n",
        "        current_prob -= 0.15 # Lower true eligibility for Non-binary individuals\n",
        "    if ages[i] > 60:\n",
        "        current_prob -= 0.1 # Lower true eligibility for older individuals\n",
        "\n",
        "    true_eligibility[i] = 1 if np.random.rand() < current_prob else 0\n",
        "\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'Gender': genders,\n",
        "    'Race': races,\n",
        "    'Age': ages,\n",
        "    'Income': income,\n",
        "    'CreditScore': credit_score,\n",
        "    'LoanAmount': loan_amount_requested,\n",
        "    'True_Eligibility': true_eligibility # This is our 'ground truth' or 'true label' (Y)\n",
        "})\n",
        "\n",
        "# Display first few rows and check true eligibility distribution\n",
        "print(\"\\nSynthetic Dataset Head:\")\n",
        "print(data.head())\n",
        "print(\"\\nTrue Eligibility Distribution:\")\n",
        "print(data['True_Eligibility'].value_counts(normalize=True))\n",
        "\n",
        "# --- Prepare data for a simple model (features X) ---\n",
        "X = data[['Income', 'CreditScore', 'LoanAmount']] # Numerical features for simplicity\n",
        "y = data['True_Eligibility']\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Split data (we'll use test set for audit)\n",
        "X_train, X_test, y_train, y_test = train_train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Train a simple Logistic Regression model ---\n",
        "model = LogisticRegression(random_state=42, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Get model predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1] # Probability of being eligible\n",
        "\n",
        "# Add sensitive attributes and true labels back to the test set for audit\n",
        "test_df = data.loc[y_test.index].copy() # Ensure original indices are used to get sensitive attrs\n",
        "test_df['y_true'] = y_test\n",
        "test_df['y_pred'] = y_pred\n",
        "test_df['y_proba'] = y_proba\n",
        "\n",
        "print(\"\\nModel Training Complete. Test set prepared for audit.\")\n",
        "print(f\"Model Accuracy on Test Set: {accuracy_score(y_test, y_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwZo1IfRjqdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0gggD_qjsrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}